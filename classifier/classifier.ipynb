{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras_facenet import FaceNet\n",
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.026938</td>\n",
       "      <td>-0.055958</td>\n",
       "      <td>0.025274</td>\n",
       "      <td>0.060849</td>\n",
       "      <td>-0.015289</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.173274</td>\n",
       "      <td>-0.009592</td>\n",
       "      <td>0.034589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052019</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.031004</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>-0.037235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.018409</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>-0.074859</td>\n",
       "      <td>-0.016567</td>\n",
       "      <td>-0.054832</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>-0.028597</td>\n",
       "      <td>0.106934</td>\n",
       "      <td>-0.036243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>-0.065546</td>\n",
       "      <td>-0.033495</td>\n",
       "      <td>-0.019550</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>-0.033387</td>\n",
       "      <td>-0.086241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.067941</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.094676</td>\n",
       "      <td>-0.035296</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.070425</td>\n",
       "      <td>0.054991</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060910</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>-0.015582</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>-0.083581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "321 -0.003574  0.026938 -0.055958  0.025274  0.060849 -0.015289  0.008360   \n",
       "81   0.040185  0.018409  0.026871 -0.074859 -0.016567 -0.054832  0.025275   \n",
       "957  0.057349  0.067941  0.001601  0.002162  0.094676 -0.035296  0.024454   \n",
       "\n",
       "            7         8         9  ...       503       504       505  \\\n",
       "321  0.173274 -0.009592  0.034589  ... -0.052019  0.024860  0.014458   \n",
       "81  -0.028597  0.106934 -0.036243  ...  0.033754  0.030762 -0.003985   \n",
       "957  0.070425  0.054991 -0.000935  ... -0.060910  0.002720  0.016191   \n",
       "\n",
       "          506       507       508       509       510       511  target  \n",
       "321  0.006939  0.056616  0.014577  0.031004  0.007175 -0.037235       1  \n",
       "81  -0.065546 -0.033495 -0.019550 -0.002377 -0.033387 -0.086241       1  \n",
       "957  0.035951  0.022001  0.014406 -0.015582  0.006471 -0.083581       0  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('celeb_embeddings.csv')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the classifier\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        57\n",
      "           1       1.00      0.98      0.99        53\n",
      "\n",
      "    accuracy                           0.99       110\n",
      "   macro avg       0.99      0.99      0.99       110\n",
      "weighted avg       0.99      0.99      0.99       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  0]\n",
      " [ 1 52]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the classifier with the entire dataset and save it\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Save the classifier\n",
    "with open('trained_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### tests #######\n",
    "\n",
    "from process_pipeline import ImageProcessor\n",
    "processor = ImageProcessor()\n",
    "\n",
    "# ##### Process the test images #####\n",
    "image_test_01 = 'test_images/01_buscemi.jpg'\n",
    "image_test_02 = 'test_images/02_pitt.jpg'\n",
    "\n",
    "pitt_test = processor.process_image(image_test_01)\n",
    "devito_test = processor.process_image(image_test_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned face has been saved in the 'test_images' directory as pitt_test_processed.jpg.\n",
      "Path to saved new image: test_images\\pitt_test_processed.jpg\n",
      "Aligned face has been saved in the 'test_images' directory as devito_test_processed.jpg.\n",
      "Path to saved new image: test_images\\devito_test_processed.jpg\n"
     ]
    }
   ],
   "source": [
    "# ##### Save the processed images #####\n",
    "output_directory = \"test_images\"\n",
    "filename = \"pitt_test_processed.jpg\"\n",
    "processor.save_image(pitt_test, output_directory, filename)\n",
    "pitt_test_processed_path = output_directory + \"\\\\\" + filename\n",
    "\n",
    "filename = \"devito_test_processed.jpg\"\n",
    "processor.save_image(devito_test, output_directory, filename)\n",
    "devito_test_processed_path = output_directory + \"\\\\\" + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract embeddings from an image\n",
    "def extract_embedding(image_path, model):\n",
    "    # Load and preprocess the image\n",
    "    image = load_img(image_path, target_size=(160, 160), color_mode='rgb')\n",
    "    image = img_to_array(image)\n",
    "    # Extract the embedding using the model\n",
    "    embedding = model.embeddings(np.array([image]))[0]\n",
    "    # Convert the embedding to a DataFrame\n",
    "    df = pd.DataFrame([embedding])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "embedder = FaceNet()\n",
    "\n",
    "# Extract the embedding using the Function\n",
    "pitt_is_allowed = extract_embedding(pitt_test_processed_path, embedder)\n",
    "devito_not_allowed = extract_embedding(devito_test_processed_path, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# save the feature names in a .txt file\n",
    "with open('feature_names.txt', 'w') as f:\n",
    "    f.write(f\"features_names = {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the embedding in a dataframe\n",
    "pitt_is_allowed = pd.DataFrame(pitt_is_allowed)\n",
    "pitt_is_allowed.columns = feature_names\n",
    "\n",
    "devito_not_allowed = pd.DataFrame(devito_not_allowed)\n",
    "devito_not_allowed.columns = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if filename.startswith('Faces_Dataset_processed/allowed'):\n",
    "##     target = 1\n",
    "## elif filename.startswith('Faces_Dataset_processed/not_allowed'):\n",
    "##     target = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = pickle.load(open('trained_classifier.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed\n"
     ]
    }
   ],
   "source": [
    "# Prediction pitt_is_allowed\n",
    "predict_test = top_model.predict(pitt_is_allowed)\n",
    "\n",
    "if predict_test[0] == 1:\n",
    "    print(\"Allowed\")\n",
    "else:\n",
    "    print(\"Not Allowed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Allowed\n"
     ]
    }
   ],
   "source": [
    "# Prediction devito_not_allowed\n",
    "predict_test = top_model.predict(devito_not_allowed)\n",
    "\n",
    "if predict_test[0] == 1:\n",
    "    print(\"Allowed\")\n",
    "else:\n",
    "    print(\"Not Allowed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
